{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56313ca8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.12.5)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fb46798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.3.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Downloading numpy-2.3.0-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 3.4/12.7 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.4/12.7 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.0/12.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.0/12.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.3/12.7 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.6/12.7 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.8/12.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.3/12.7 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.1/12.7 MB 4.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.2/12.7 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.0/12.7 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.7 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12fefd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in .\\.venv\\lib\\site-packages (from pandas) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in .\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.0-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 3.7/11.0 MB 24.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 13.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.8/11.0 MB 9.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.0/11.0 MB 8.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.8/11.0 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.0 MB 4.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.6/11.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.0 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 4.2 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   ---------------------------------------- 3/3 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.3.0 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b3fa697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in .\\.venv\\lib\\site-packages (from scikit-learn) (2.3.0)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.0-cp312-cp312-win_amd64.whl (10.7 MB)\n",
      "   ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.6/10.7 MB 15.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.7/10.7 MB 9.1 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.7/10.7 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.0/10.7 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.5/10.7 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.3/10.7 MB 4.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.3/10.7 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.7/10.7 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.2/10.7 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.7/10.7 MB 5.0 MB/s eta 0:00:00\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached scipy-1.15.3-cp312-cp312-win_amd64.whl (41.0 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ---------------------------------------- 4/4 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11734218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.4-cp312-cp312-win_amd64.whl.metadata (108 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in .\\.venv\\lib\\site-packages (from matplotlib) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in .\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp312-cp312-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in .\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in .\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 3.7/8.1 MB 21.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.7/8.1 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.8/8.1 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.6/8.1 MB 7.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.8/8.1 MB 6.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.1/8.1 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.1 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.2-cp312-cp312-win_amd64.whl (223 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.4-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.2 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 5.5 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
      "Downloading pillow-11.2.1-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 1.3/2.7 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------------- 7/7 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.4 kiwisolver-1.4.8 matplotlib-3.10.3 pillow-11.2.1 pyparsing-3.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f240b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in .\\.venv\\lib\\site-packages (from seaborn) (2.3.0)\n",
      "Requirement already satisfied: pandas>=1.2 in .\\.venv\\lib\\site-packages (from seaborn) (2.3.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in .\\.venv\\lib\\site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in .\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in .\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in .\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in .\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in .\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in .\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in .\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in .\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in .\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in .\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c3e533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tenserflow (from versions: none)\n",
      "ERROR: No matching distribution found for tenserflow\n"
     ]
    }
   ],
   "source": [
    "pip install tenserflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb07154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Flask\n",
      "  Using cached flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting blinker>=1.9.0 (from Flask)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting click>=8.1.3 (from Flask)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting jinja2>=3.1.2 (from Flask)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting markupsafe>=2.1.1 (from Flask)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting werkzeug>=3.1.0 (from Flask)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: colorama in .\\.venv\\lib\\site-packages (from click>=8.1.3->Flask) (0.4.6)\n",
      "Using cached flask-3.1.1-py3-none-any.whl (103 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: markupsafe, itsdangerous, click, blinker, werkzeug, jinja2, Flask\n",
      "\n",
      "   ----- ---------------------------------- 1/7 [itsdangerous]\n",
      "   ----------- ---------------------------- 2/7 [click]\n",
      "   ----------- ---------------------------- 2/7 [click]\n",
      "   ----------------- ---------------------- 3/7 [blinker]\n",
      "   ---------------------- ----------------- 4/7 [werkzeug]\n",
      "   ---------------------- ----------------- 4/7 [werkzeug]\n",
      "   ---------------------- ----------------- 4/7 [werkzeug]\n",
      "   ---------------------- ----------------- 4/7 [werkzeug]\n",
      "   ---------------------- ----------------- 4/7 [werkzeug]\n",
      "   ---------------------- ----------------- 4/7 [werkzeug]\n",
      "   ---------------------- ----------------- 4/7 [werkzeug]\n",
      "   ---------------------------- ----------- 5/7 [jinja2]\n",
      "   ---------------------------- ----------- 5/7 [jinja2]\n",
      "   ---------------------------- ----------- 5/7 [jinja2]\n",
      "   ---------------------------- ----------- 5/7 [jinja2]\n",
      "   ---------------------------------- ----- 6/7 [Flask]\n",
      "   ---------------------------------- ----- 6/7 [Flask]\n",
      "   ---------------------------------- ----- 6/7 [Flask]\n",
      "   ---------------------------------- ----- 6/7 [Flask]\n",
      "   ---------------------------------------- 7/7 [Flask]\n",
      "\n",
      "Successfully installed Flask-3.1.1 blinker-1.9.0 click-8.2.1 itsdangerous-2.2.0 jinja2-3.1.6 markupsafe-3.0.2 werkzeug-3.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66365a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting certifi>=14.05.14 (from kaggle)\n",
      "  Downloading certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting charset-normalizer (from kaggle)\n",
      "  Using cached charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna (from kaggle)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting protobuf (from kaggle)\n",
      "  Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in .\\.venv\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting requests (from kaggle)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting setuptools>=21.0.0 (from kaggle)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.10 in .\\.venv\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Collecting text-unidecode (from kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tqdm (from kaggle)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting urllib3>=1.15.1 (from kaggle)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting webencodings (from kaggle)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: colorama in .\\.venv\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
      "Downloading certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl (105 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, text-unidecode, urllib3, tqdm, setuptools, python-slugify, protobuf, idna, charset-normalizer, certifi, bleach, requests, kaggle\n",
      "\n",
      "   ------ ---------------------------------  2/13 [urllib3]\n",
      "   ------ ---------------------------------  2/13 [urllib3]\n",
      "   ------ ---------------------------------  2/13 [urllib3]\n",
      "   ------ ---------------------------------  2/13 [urllib3]\n",
      "   ------ ---------------------------------  2/13 [urllib3]\n",
      "   --------- ------------------------------  3/13 [tqdm]\n",
      "   --------- ------------------------------  3/13 [tqdm]\n",
      "   --------- ------------------------------  3/13 [tqdm]\n",
      "   --------- ------------------------------  3/13 [tqdm]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   ------------ ---------------------------  4/13 [setuptools]\n",
      "   --------------- ------------------------  5/13 [python-slugify]\n",
      "   ------------------ ---------------------  6/13 [protobuf]\n",
      "   ------------------ ---------------------  6/13 [protobuf]\n",
      "   ------------------ ---------------------  6/13 [protobuf]\n",
      "   ------------------ ---------------------  6/13 [protobuf]\n",
      "   ------------------ ---------------------  6/13 [protobuf]\n",
      "   ------------------ ---------------------  6/13 [protobuf]\n",
      "   ------------------ ---------------------  6/13 [protobuf]\n",
      "   ------------------ ---------------------  6/13 [protobuf]\n",
      "   --------------------- ------------------  7/13 [idna]\n",
      "   --------------------- ------------------  7/13 [idna]\n",
      "   ------------------------ ---------------  8/13 [charset-normalizer]\n",
      "   ------------------------ ---------------  8/13 [charset-normalizer]\n",
      "   ------------------------------ --------- 10/13 [bleach]\n",
      "   ------------------------------ --------- 10/13 [bleach]\n",
      "   ------------------------------ --------- 10/13 [bleach]\n",
      "   ------------------------------ --------- 10/13 [bleach]\n",
      "   ------------------------------ --------- 10/13 [bleach]\n",
      "   ------------------------------ --------- 10/13 [bleach]\n",
      "   ------------------------------ --------- 10/13 [bleach]\n",
      "   --------------------------------- ------ 11/13 [requests]\n",
      "   --------------------------------- ------ 11/13 [requests]\n",
      "   --------------------------------- ------ 11/13 [requests]\n",
      "   ------------------------------------ --- 12/13 [kaggle]\n",
      "   ------------------------------------ --- 12/13 [kaggle]\n",
      "   ------------------------------------ --- 12/13 [kaggle]\n",
      "   ------------------------------------ --- 12/13 [kaggle]\n",
      "   ------------------------------------ --- 12/13 [kaggle]\n",
      "   ------------------------------------ --- 12/13 [kaggle]\n",
      "   ------------------------------------ --- 12/13 [kaggle]\n",
      "   ------------------------------------ --- 12/13 [kaggle]\n",
      "   ------------------------------------ --- 12/13 [kaggle]\n",
      "   ------------------------------------ --- 12/13 [kaggle]\n",
      "   ------------------------------------ --- 12/13 [kaggle]\n",
      "   ------------------------------------ --- 12/13 [kaggle]\n",
      "   ------------------------------------ --- 12/13 [kaggle]\n",
      "   ---------------------------------------- 13/13 [kaggle]\n",
      "\n",
      "Successfully installed bleach-6.2.0 certifi-2025.6.15 charset-normalizer-3.4.2 idna-3.10 kaggle-1.7.4.5 protobuf-6.31.1 python-slugify-8.0.4 requests-2.32.4 setuptools-80.9.0 text-unidecode-1.3 tqdm-4.67.1 urllib3-2.4.0 webencodings-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dcebf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ebcbe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11724a77",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Input, Lambda, Dense, Flatten\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model, Sequential\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapplications\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvgg16\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VGG16, preprocess_input\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5591747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in .\\.venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in .\\.venv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in .\\.venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in .\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow)\n",
      "  Downloading typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.73.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.14.0-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in .\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.16.0-cp312-cp312-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in .\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in .\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.4/376.0 MB 22.5 MB/s eta 0:00:17\n",
      "    --------------------------------------- 4.7/376.0 MB 12.4 MB/s eta 0:00:30\n",
      "    --------------------------------------- 5.8/376.0 MB 9.5 MB/s eta 0:00:39\n",
      "    --------------------------------------- 6.3/376.0 MB 7.6 MB/s eta 0:00:49\n",
      "    --------------------------------------- 6.8/376.0 MB 6.9 MB/s eta 0:00:54\n",
      "    --------------------------------------- 7.6/376.0 MB 6.2 MB/s eta 0:01:00\n",
      "    --------------------------------------- 8.7/376.0 MB 5.9 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 9.7/376.0 MB 5.9 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 11.3/376.0 MB 6.0 MB/s eta 0:01:02\n",
      "   - -------------------------------------- 12.1/376.0 MB 5.8 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 12.8/376.0 MB 5.6 MB/s eta 0:01:06\n",
      "   - -------------------------------------- 13.6/376.0 MB 5.5 MB/s eta 0:01:07\n",
      "   - -------------------------------------- 14.7/376.0 MB 5.3 MB/s eta 0:01:08\n",
      "   - -------------------------------------- 15.7/376.0 MB 5.4 MB/s eta 0:01:08\n",
      "   - -------------------------------------- 17.0/376.0 MB 5.4 MB/s eta 0:01:07\n",
      "   - -------------------------------------- 17.8/376.0 MB 5.3 MB/s eta 0:01:08\n",
      "   - -------------------------------------- 18.6/376.0 MB 5.2 MB/s eta 0:01:09\n",
      "   -- ------------------------------------- 19.9/376.0 MB 5.2 MB/s eta 0:01:08\n",
      "   -- ------------------------------------- 21.5/376.0 MB 5.3 MB/s eta 0:01:07\n",
      "   -- ------------------------------------- 22.5/376.0 MB 5.4 MB/s eta 0:01:06\n",
      "   -- ------------------------------------- 23.6/376.0 MB 5.3 MB/s eta 0:01:07\n",
      "   -- ------------------------------------- 24.1/376.0 MB 5.2 MB/s eta 0:01:08\n",
      "   -- ------------------------------------- 24.6/376.0 MB 5.1 MB/s eta 0:01:09\n",
      "   -- ------------------------------------- 25.7/376.0 MB 5.1 MB/s eta 0:01:10\n",
      "   -- ------------------------------------- 26.7/376.0 MB 5.0 MB/s eta 0:01:10\n",
      "   --- ------------------------------------ 28.3/376.0 MB 5.1 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 29.6/376.0 MB 5.2 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 30.7/376.0 MB 5.2 MB/s eta 0:01:07\n",
      "   --- ------------------------------------ 31.5/376.0 MB 5.1 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 32.5/376.0 MB 5.1 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 33.3/376.0 MB 5.1 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 34.3/376.0 MB 5.1 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 35.1/376.0 MB 5.1 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 35.9/376.0 MB 5.0 MB/s eta 0:01:08\n",
      "   --- ------------------------------------ 36.7/376.0 MB 5.0 MB/s eta 0:01:09\n",
      "   ---- ----------------------------------- 38.0/376.0 MB 5.0 MB/s eta 0:01:08\n",
      "   ---- ----------------------------------- 39.6/376.0 MB 5.1 MB/s eta 0:01:07\n",
      "   ---- ----------------------------------- 40.9/376.0 MB 5.1 MB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 42.2/376.0 MB 5.1 MB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 42.7/376.0 MB 5.1 MB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 43.5/376.0 MB 5.0 MB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 44.3/376.0 MB 5.0 MB/s eta 0:01:07\n",
      "   ---- ----------------------------------- 45.6/376.0 MB 5.0 MB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 46.7/376.0 MB 5.0 MB/s eta 0:01:06\n",
      "   ----- ---------------------------------- 47.7/376.0 MB 5.0 MB/s eta 0:01:06\n",
      "   ----- ---------------------------------- 49.0/376.0 MB 5.1 MB/s eta 0:01:05\n",
      "   ----- ---------------------------------- 50.1/376.0 MB 5.0 MB/s eta 0:01:05\n",
      "   ----- ---------------------------------- 50.9/376.0 MB 5.0 MB/s eta 0:01:05\n",
      "   ----- ---------------------------------- 51.4/376.0 MB 5.0 MB/s eta 0:01:06\n",
      "   ----- ---------------------------------- 51.9/376.0 MB 4.9 MB/s eta 0:01:06\n",
      "   ----- ---------------------------------- 53.0/376.0 MB 4.9 MB/s eta 0:01:06\n",
      "   ----- ---------------------------------- 54.0/376.0 MB 4.9 MB/s eta 0:01:06\n",
      "   ----- ---------------------------------- 55.3/376.0 MB 5.0 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 56.6/376.0 MB 5.0 MB/s eta 0:01:05\n",
      "   ------ --------------------------------- 57.9/376.0 MB 5.0 MB/s eta 0:01:04\n",
      "   ------ --------------------------------- 59.0/376.0 MB 5.0 MB/s eta 0:01:04\n",
      "   ------ --------------------------------- 59.8/376.0 MB 5.0 MB/s eta 0:01:04\n",
      "   ------ --------------------------------- 60.8/376.0 MB 5.0 MB/s eta 0:01:04\n",
      "   ------ --------------------------------- 61.9/376.0 MB 5.0 MB/s eta 0:01:04\n",
      "   ------ --------------------------------- 62.9/376.0 MB 5.0 MB/s eta 0:01:03\n",
      "   ------ --------------------------------- 64.0/376.0 MB 5.0 MB/s eta 0:01:03\n",
      "   ------ --------------------------------- 65.3/376.0 MB 5.0 MB/s eta 0:01:02\n",
      "   ------- -------------------------------- 66.1/376.0 MB 5.0 MB/s eta 0:01:03\n",
      "   ------- -------------------------------- 66.3/376.0 MB 5.0 MB/s eta 0:01:03\n",
      "   ------- -------------------------------- 67.1/376.0 MB 4.9 MB/s eta 0:01:03\n",
      "   ------- -------------------------------- 68.2/376.0 MB 4.9 MB/s eta 0:01:03\n",
      "   ------- -------------------------------- 69.5/376.0 MB 4.9 MB/s eta 0:01:03\n",
      "   ------- -------------------------------- 70.8/376.0 MB 5.0 MB/s eta 0:01:02\n",
      "   ------- -------------------------------- 72.1/376.0 MB 5.0 MB/s eta 0:01:02\n",
      "   ------- -------------------------------- 73.1/376.0 MB 5.0 MB/s eta 0:01:01\n",
      "   ------- -------------------------------- 74.2/376.0 MB 5.0 MB/s eta 0:01:01\n",
      "   ------- -------------------------------- 75.0/376.0 MB 5.0 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 75.8/376.0 MB 4.9 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 76.8/376.0 MB 4.9 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 78.1/376.0 MB 5.0 MB/s eta 0:01:01\n",
      "   -------- ------------------------------- 79.4/376.0 MB 5.0 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 80.2/376.0 MB 5.0 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 81.0/376.0 MB 4.9 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 82.1/376.0 MB 4.9 MB/s eta 0:01:00\n",
      "   -------- ------------------------------- 83.4/376.0 MB 5.0 MB/s eta 0:01:00\n",
      "   --------- ------------------------------ 84.9/376.0 MB 5.0 MB/s eta 0:00:59\n",
      "   --------- ------------------------------ 86.2/376.0 MB 5.0 MB/s eta 0:00:58\n",
      "   --------- ------------------------------ 86.8/376.0 MB 5.0 MB/s eta 0:00:59\n",
      "   --------- ------------------------------ 87.0/376.0 MB 4.9 MB/s eta 0:00:59\n",
      "   --------- ------------------------------ 87.6/376.0 MB 4.9 MB/s eta 0:00:59\n",
      "   --------- ------------------------------ 88.3/376.0 MB 4.9 MB/s eta 0:00:59\n",
      "   --------- ------------------------------ 89.7/376.0 MB 4.9 MB/s eta 0:00:59\n",
      "   --------- ------------------------------ 91.0/376.0 MB 4.9 MB/s eta 0:00:59\n",
      "   --------- ------------------------------ 92.5/376.0 MB 4.9 MB/s eta 0:00:58\n",
      "   --------- ------------------------------ 93.3/376.0 MB 4.9 MB/s eta 0:00:58\n",
      "   ---------- ----------------------------- 94.4/376.0 MB 4.9 MB/s eta 0:00:58\n",
      "   ---------- ----------------------------- 95.7/376.0 MB 4.9 MB/s eta 0:00:57\n",
      "   ---------- ----------------------------- 96.7/376.0 MB 4.9 MB/s eta 0:00:57\n",
      "   ---------- ----------------------------- 97.3/376.0 MB 4.9 MB/s eta 0:00:57\n",
      "   ---------- ----------------------------- 98.3/376.0 MB 4.9 MB/s eta 0:00:57\n",
      "   ---------- ----------------------------- 99.6/376.0 MB 4.9 MB/s eta 0:00:57\n",
      "   ---------- ----------------------------- 100.7/376.0 MB 4.9 MB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 102.0/376.0 MB 4.9 MB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 103.0/376.0 MB 4.9 MB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 104.1/376.0 MB 4.9 MB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 104.6/376.0 MB 4.9 MB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 105.4/376.0 MB 4.9 MB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 106.4/376.0 MB 4.9 MB/s eta 0:00:55\n",
      "   ----------- ---------------------------- 107.7/376.0 MB 4.9 MB/s eta 0:00:55\n",
      "   ----------- ---------------------------- 109.1/376.0 MB 4.9 MB/s eta 0:00:55\n",
      "   ----------- ---------------------------- 110.4/376.0 MB 4.9 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 111.1/376.0 MB 4.9 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 111.9/376.0 MB 4.9 MB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 112.7/376.0 MB 4.9 MB/s eta 0:00:54\n",
      "   ------------ --------------------------- 114.0/376.0 MB 4.9 MB/s eta 0:00:54\n",
      "   ------------ --------------------------- 115.1/376.0 MB 4.9 MB/s eta 0:00:53\n",
      "   ------------ --------------------------- 116.1/376.0 MB 4.9 MB/s eta 0:00:53\n",
      "   ------------ --------------------------- 116.9/376.0 MB 4.9 MB/s eta 0:00:53\n",
      "   ------------ --------------------------- 118.2/376.0 MB 4.9 MB/s eta 0:00:53\n",
      "   ------------ --------------------------- 119.5/376.0 MB 4.9 MB/s eta 0:00:52\n",
      "   ------------ --------------------------- 120.3/376.0 MB 4.9 MB/s eta 0:00:52\n",
      "   ------------ --------------------------- 121.1/376.0 MB 4.9 MB/s eta 0:00:52\n",
      "   ------------ --------------------------- 122.2/376.0 MB 4.9 MB/s eta 0:00:52\n",
      "   ------------- -------------------------- 123.5/376.0 MB 4.9 MB/s eta 0:00:52\n",
      "   ------------- -------------------------- 124.3/376.0 MB 4.9 MB/s eta 0:00:52\n",
      "   ------------- -------------------------- 125.0/376.0 MB 4.9 MB/s eta 0:00:52\n",
      "   ------------- -------------------------- 126.4/376.0 MB 4.9 MB/s eta 0:00:51\n",
      "   ------------- -------------------------- 127.7/376.0 MB 4.9 MB/s eta 0:00:51\n",
      "   ------------- -------------------------- 128.7/376.0 MB 4.9 MB/s eta 0:00:51\n",
      "   ------------- -------------------------- 129.5/376.0 MB 4.9 MB/s eta 0:00:51\n",
      "   ------------- -------------------------- 130.3/376.0 MB 4.9 MB/s eta 0:00:50\n",
      "   -------------- ------------------------- 131.6/376.0 MB 4.9 MB/s eta 0:00:50\n",
      "   -------------- ------------------------- 132.9/376.0 MB 4.9 MB/s eta 0:00:50\n",
      "   -------------- ------------------------- 133.4/376.0 MB 4.9 MB/s eta 0:00:50\n",
      "   -------------- ------------------------- 134.0/376.0 MB 4.9 MB/s eta 0:00:50\n",
      "   -------------- ------------------------- 134.7/376.0 MB 4.9 MB/s eta 0:00:50\n",
      "   -------------- ------------------------- 135.8/376.0 MB 4.9 MB/s eta 0:00:50\n",
      "   -------------- ------------------------- 136.8/376.0 MB 4.9 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 138.1/376.0 MB 4.9 MB/s eta 0:00:49\n",
      "   -------------- ------------------------- 140.0/376.0 MB 4.9 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 141.0/376.0 MB 4.9 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 141.8/376.0 MB 4.9 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 142.6/376.0 MB 4.9 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 143.9/376.0 MB 4.9 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 145.0/376.0 MB 4.9 MB/s eta 0:00:47\n",
      "   --------------- ------------------------ 146.3/376.0 MB 4.9 MB/s eta 0:00:47\n",
      "   --------------- ------------------------ 147.6/376.0 MB 4.9 MB/s eta 0:00:47\n",
      "   --------------- ------------------------ 148.1/376.0 MB 4.9 MB/s eta 0:00:47\n",
      "   --------------- ------------------------ 148.9/376.0 MB 4.8 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 149.2/376.0 MB 4.8 MB/s eta 0:00:48\n",
      "   --------------- ------------------------ 150.2/376.0 MB 4.8 MB/s eta 0:00:47\n",
      "   ---------------- ----------------------- 151.3/376.0 MB 4.8 MB/s eta 0:00:47\n",
      "   ---------------- ----------------------- 152.8/376.0 MB 4.8 MB/s eta 0:00:47\n",
      "   ---------------- ----------------------- 154.1/376.0 MB 4.9 MB/s eta 0:00:46\n",
      "   ---------------- ----------------------- 155.5/376.0 MB 4.9 MB/s eta 0:00:46\n",
      "   ---------------- ----------------------- 157.0/376.0 MB 4.9 MB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 158.1/376.0 MB 4.9 MB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 158.6/376.0 MB 4.9 MB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 159.1/376.0 MB 4.9 MB/s eta 0:00:45\n",
      "   ----------------- ---------------------- 160.2/376.0 MB 4.9 MB/s eta 0:00:45\n",
      "   ----------------- ---------------------- 161.2/376.0 MB 4.9 MB/s eta 0:00:45\n",
      "   ----------------- ---------------------- 162.5/376.0 MB 4.9 MB/s eta 0:00:44\n",
      "   ----------------- ---------------------- 163.6/376.0 MB 4.9 MB/s eta 0:00:44\n",
      "   ----------------- ---------------------- 164.6/376.0 MB 4.9 MB/s eta 0:00:44\n",
      "   ----------------- ---------------------- 165.4/376.0 MB 4.9 MB/s eta 0:00:44\n",
      "   ----------------- ---------------------- 166.2/376.0 MB 4.9 MB/s eta 0:00:44\n",
      "   ----------------- ---------------------- 167.2/376.0 MB 4.8 MB/s eta 0:00:44\n",
      "   ----------------- ---------------------- 168.6/376.0 MB 4.8 MB/s eta 0:00:43\n",
      "   ------------------ --------------------- 169.9/376.0 MB 4.9 MB/s eta 0:00:43\n",
      "   ------------------ --------------------- 170.7/376.0 MB 4.9 MB/s eta 0:00:43\n",
      "   ------------------ --------------------- 171.7/376.0 MB 4.9 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 172.8/376.0 MB 4.9 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 173.5/376.0 MB 4.9 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 174.6/376.0 MB 4.9 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 175.9/376.0 MB 4.9 MB/s eta 0:00:42\n",
      "   ------------------ --------------------- 176.9/376.0 MB 4.9 MB/s eta 0:00:41\n",
      "   ------------------ --------------------- 178.3/376.0 MB 4.9 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 179.0/376.0 MB 4.9 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 179.8/376.0 MB 4.9 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 180.6/376.0 MB 4.9 MB/s eta 0:00:41\n",
      "   ------------------- -------------------- 181.9/376.0 MB 4.9 MB/s eta 0:00:40\n",
      "   ------------------- -------------------- 182.7/376.0 MB 4.9 MB/s eta 0:00:40\n",
      "   ------------------- -------------------- 183.8/376.0 MB 4.9 MB/s eta 0:00:40\n",
      "   ------------------- -------------------- 184.8/376.0 MB 4.9 MB/s eta 0:00:40\n",
      "   ------------------- -------------------- 186.1/376.0 MB 4.9 MB/s eta 0:00:40\n",
      "   ------------------- -------------------- 187.2/376.0 MB 4.9 MB/s eta 0:00:39\n",
      "   ------------------- -------------------- 188.0/376.0 MB 4.9 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 188.7/376.0 MB 4.8 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 189.5/376.0 MB 4.9 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 190.8/376.0 MB 4.9 MB/s eta 0:00:39\n",
      "   -------------------- ------------------- 192.2/376.0 MB 4.9 MB/s eta 0:00:38\n",
      "   -------------------- ------------------- 193.7/376.0 MB 4.9 MB/s eta 0:00:38\n",
      "   -------------------- ------------------- 194.5/376.0 MB 4.9 MB/s eta 0:00:38\n",
      "   -------------------- ------------------- 195.0/376.0 MB 4.8 MB/s eta 0:00:38\n",
      "   -------------------- ------------------- 196.1/376.0 MB 4.9 MB/s eta 0:00:38\n",
      "   -------------------- ------------------- 197.1/376.0 MB 4.9 MB/s eta 0:00:37\n",
      "   --------------------- ------------------ 198.4/376.0 MB 4.9 MB/s eta 0:00:37\n",
      "   --------------------- ------------------ 199.8/376.0 MB 4.9 MB/s eta 0:00:36\n",
      "   --------------------- ------------------ 200.3/376.0 MB 4.9 MB/s eta 0:00:36\n",
      "   --------------------- ------------------ 201.3/376.0 MB 4.9 MB/s eta 0:00:36\n",
      "   --------------------- ------------------ 202.6/376.0 MB 4.9 MB/s eta 0:00:36\n",
      "   --------------------- ------------------ 203.4/376.0 MB 4.9 MB/s eta 0:00:36\n",
      "   --------------------- ------------------ 203.9/376.0 MB 4.8 MB/s eta 0:00:36\n",
      "   --------------------- ------------------ 204.7/376.0 MB 4.8 MB/s eta 0:00:36\n",
      "   --------------------- ------------------ 205.5/376.0 MB 4.8 MB/s eta 0:00:36\n",
      "   --------------------- ------------------ 206.6/376.0 MB 4.8 MB/s eta 0:00:36\n",
      "   ---------------------- ----------------- 208.1/376.0 MB 4.9 MB/s eta 0:00:35\n",
      "   ---------------------- ----------------- 210.0/376.0 MB 4.9 MB/s eta 0:00:35\n",
      "   ---------------------- ----------------- 211.0/376.0 MB 4.9 MB/s eta 0:00:34\n",
      "   ---------------------- ----------------- 212.1/376.0 MB 4.9 MB/s eta 0:00:34\n",
      "   ---------------------- ----------------- 212.9/376.0 MB 4.9 MB/s eta 0:00:34\n",
      "   ---------------------- ----------------- 213.9/376.0 MB 4.9 MB/s eta 0:00:34\n",
      "   ---------------------- ----------------- 214.7/376.0 MB 4.9 MB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 215.5/376.0 MB 4.9 MB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 216.5/376.0 MB 4.9 MB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 217.3/376.0 MB 4.9 MB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 218.6/376.0 MB 4.9 MB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 219.9/376.0 MB 4.9 MB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 220.7/376.0 MB 4.9 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 221.8/376.0 MB 4.9 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 222.6/376.0 MB 4.9 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 223.9/376.0 MB 4.9 MB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 225.2/376.0 MB 4.9 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 226.5/376.0 MB 4.9 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 227.3/376.0 MB 4.9 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 228.1/376.0 MB 4.9 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 228.9/376.0 MB 4.9 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 229.6/376.0 MB 4.8 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 230.4/376.0 MB 4.8 MB/s eta 0:00:31\n",
      "   ------------------------ --------------- 231.2/376.0 MB 4.8 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 232.5/376.0 MB 4.9 MB/s eta 0:00:30\n",
      "   ------------------------ --------------- 234.1/376.0 MB 4.9 MB/s eta 0:00:30\n",
      "   ------------------------- -------------- 235.4/376.0 MB 4.9 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 235.9/376.0 MB 4.9 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 236.5/376.0 MB 4.9 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 237.2/376.0 MB 4.9 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 238.0/376.0 MB 4.8 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 239.3/376.0 MB 4.8 MB/s eta 0:00:29\n",
      "   ------------------------- -------------- 240.9/376.0 MB 4.9 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 242.5/376.0 MB 4.9 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 243.5/376.0 MB 4.9 MB/s eta 0:00:28\n",
      "   ------------------------- -------------- 244.1/376.0 MB 4.9 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 244.8/376.0 MB 4.9 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 245.6/376.0 MB 4.8 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 246.9/376.0 MB 4.8 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 248.3/376.0 MB 4.9 MB/s eta 0:00:27\n",
      "   -------------------------- ------------- 249.8/376.0 MB 4.9 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 250.9/376.0 MB 4.9 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 251.7/376.0 MB 4.9 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 252.2/376.0 MB 4.9 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 252.7/376.0 MB 4.9 MB/s eta 0:00:26\n",
      "   -------------------------- ------------- 253.5/376.0 MB 4.8 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 254.5/376.0 MB 4.8 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 256.1/376.0 MB 4.8 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 257.4/376.0 MB 4.9 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 257.9/376.0 MB 4.9 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 258.7/376.0 MB 4.9 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 259.8/376.0 MB 4.8 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 261.1/376.0 MB 4.8 MB/s eta 0:00:24\n",
      "   --------------------------- ------------ 262.4/376.0 MB 4.9 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 263.5/376.0 MB 4.9 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 264.2/376.0 MB 4.9 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 265.3/376.0 MB 4.9 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 266.3/376.0 MB 4.9 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 267.9/376.0 MB 4.9 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 269.0/376.0 MB 4.9 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 269.7/376.0 MB 4.9 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 270.5/376.0 MB 4.9 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 271.3/376.0 MB 4.9 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 272.4/376.0 MB 4.9 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 273.7/376.0 MB 4.9 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 275.0/376.0 MB 4.9 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 275.8/376.0 MB 4.9 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 276.3/376.0 MB 4.9 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 277.3/376.0 MB 4.8 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 278.4/376.0 MB 4.8 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 279.7/376.0 MB 4.9 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 280.8/376.0 MB 4.9 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 281.8/376.0 MB 4.9 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 282.9/376.0 MB 4.9 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 283.9/376.0 MB 4.9 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 284.7/376.0 MB 4.9 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 285.5/376.0 MB 4.8 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 286.5/376.0 MB 4.8 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 287.6/376.0 MB 4.9 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 288.9/376.0 MB 4.9 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 289.7/376.0 MB 4.9 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 290.5/376.0 MB 4.8 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 291.5/376.0 MB 4.8 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 292.8/376.0 MB 4.8 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 294.4/376.0 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 295.2/376.0 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 295.7/376.0 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 296.2/376.0 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 297.0/376.0 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 298.1/376.0 MB 4.8 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 299.4/376.0 MB 4.8 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 300.7/376.0 MB 4.8 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 302.3/376.0 MB 4.8 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 303.3/376.0 MB 4.8 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 304.1/376.0 MB 4.9 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 304.9/376.0 MB 4.9 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 305.9/376.0 MB 4.9 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 307.2/376.0 MB 4.9 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 308.5/376.0 MB 4.9 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 309.6/376.0 MB 4.9 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 310.6/376.0 MB 4.9 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 311.2/376.0 MB 4.9 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 312.2/376.0 MB 4.9 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 313.3/376.0 MB 4.9 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 314.3/376.0 MB 4.9 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 315.4/376.0 MB 4.9 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 316.4/376.0 MB 4.9 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 317.5/376.0 MB 4.9 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 318.5/376.0 MB 4.9 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 319.6/376.0 MB 4.9 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 320.3/376.0 MB 4.9 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 321.4/376.0 MB 4.9 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 322.7/376.0 MB 4.9 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 323.7/376.0 MB 4.8 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 325.1/376.0 MB 4.9 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 326.4/376.0 MB 4.9 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 327.2/376.0 MB 4.9 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 327.7/376.0 MB 4.9 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 328.5/376.0 MB 4.9 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 329.5/376.0 MB 4.9 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 330.6/376.0 MB 4.9 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 331.9/376.0 MB 4.9 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 332.7/376.0 MB 4.9 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 333.7/376.0 MB 4.8 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 334.5/376.0 MB 4.9 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 335.3/376.0 MB 4.8 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 336.1/376.0 MB 4.8 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 337.1/376.0 MB 4.8 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 338.4/376.0 MB 4.8 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 340.3/376.0 MB 4.9 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 341.6/376.0 MB 4.9 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 342.4/376.0 MB 4.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 343.4/376.0 MB 4.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 344.7/376.0 MB 4.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 345.5/376.0 MB 4.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 346.3/376.0 MB 4.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 347.3/376.0 MB 4.9 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 348.4/376.0 MB 4.9 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 349.7/376.0 MB 4.9 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 351.0/376.0 MB 4.9 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 351.8/376.0 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 352.6/376.0 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 353.4/376.0 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 354.4/376.0 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 355.7/376.0 MB 4.8 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 357.3/376.0 MB 4.9 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 358.4/376.0 MB 4.9 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 359.1/376.0 MB 4.9 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 360.2/376.0 MB 4.9 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 361.0/376.0 MB 4.9 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 362.0/376.0 MB 4.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 363.3/376.0 MB 4.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 364.1/376.0 MB 4.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 365.4/376.0 MB 4.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 366.2/376.0 MB 4.9 MB/s eta 0:00:03\n",
      "   ---------------------------------------  367.3/376.0 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  368.1/376.0 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  369.1/376.0 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  370.1/376.0 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  371.5/376.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  372.0/376.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  372.5/376.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  373.6/376.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  374.6/376.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 376.0/376.0 MB 4.6 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.73.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 1.6/4.3 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.9/4.3 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.2/4.3 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/12.6 MB 5.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.4/12.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.2/12.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.6/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.6/12.6 MB 5.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.7/12.6 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/5.5 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.6/5.5 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.5 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 5.0 MB/s eta 0:00:00\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp312-cp312-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.6/2.9 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 8.3 MB/s eta 0:00:00\n",
      "Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 7.9 MB/s eta 0:00:00\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.16.0-cp312-cp312-win_amd64.whl (315 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, typing-extensions, termcolor, tensorboard-data-server, protobuf, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, absl-py, tensorboard, optree, ml-dtypes, markdown-it-py, h5py, astunparse, rich, keras, tensorflow\n",
      "\n",
      "   - --------------------------------------  1/26 [libclang]\n",
      "   - --------------------------------------  1/26 [libclang]\n",
      "   - --------------------------------------  1/26 [libclang]\n",
      "   --- ------------------------------------  2/26 [flatbuffers]\n",
      "   ---- -----------------------------------  3/26 [wrapt]\n",
      "   ------ ---------------------------------  4/26 [wheel]\n",
      "   ------ ---------------------------------  4/26 [wheel]\n",
      "   ------ ---------------------------------  4/26 [wheel]\n",
      "   ------ ---------------------------------  4/26 [wheel]\n",
      "   ------ ---------------------------------  4/26 [wheel]\n",
      "   ------ ---------------------------------  4/26 [wheel]\n",
      "   --------- ------------------------------  6/26 [termcolor]\n",
      "  Attempting uninstall: protobuf\n",
      "   --------- ------------------------------  6/26 [termcolor]\n",
      "    Found existing installation: protobuf 6.31.1\n",
      "   --------- ------------------------------  6/26 [termcolor]\n",
      "    Uninstalling protobuf-6.31.1:\n",
      "   --------- ------------------------------  6/26 [termcolor]\n",
      "      Successfully uninstalled protobuf-6.31.1\n",
      "   --------- ------------------------------  6/26 [termcolor]\n",
      "   ------------ ---------------------------  8/26 [protobuf]\n",
      "   ------------ ---------------------------  8/26 [protobuf]\n",
      "   ------------ ---------------------------  8/26 [protobuf]\n",
      "   ------------ ---------------------------  8/26 [protobuf]\n",
      "   ------------ ---------------------------  8/26 [protobuf]\n",
      "   ------------ ---------------------------  8/26 [protobuf]\n",
      "   ------------ ---------------------------  8/26 [protobuf]\n",
      "   ------------- --------------------------  9/26 [opt-einsum]\n",
      "   ------------- --------------------------  9/26 [opt-einsum]\n",
      "   ------------- --------------------------  9/26 [opt-einsum]\n",
      "  Attempting uninstall: numpy\n",
      "   ------------- --------------------------  9/26 [opt-einsum]\n",
      "    Found existing installation: numpy 2.3.0\n",
      "   ------------- --------------------------  9/26 [opt-einsum]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "    Uninstalling numpy-2.3.0:\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "      Successfully uninstalled numpy-2.3.0\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   --------------- ------------------------ 10/26 [numpy]\n",
      "   ---------------- ----------------------- 11/26 [mdurl]\n",
      "   ------------------ --------------------- 12/26 [markdown]\n",
      "   ------------------ --------------------- 12/26 [markdown]\n",
      "   ------------------ --------------------- 12/26 [markdown]\n",
      "   ------------------ --------------------- 12/26 [markdown]\n",
      "   ------------------ --------------------- 12/26 [markdown]\n",
      "   -------------------- ------------------- 13/26 [grpcio]\n",
      "   -------------------- ------------------- 13/26 [grpcio]\n",
      "   -------------------- ------------------- 13/26 [grpcio]\n",
      "   -------------------- ------------------- 13/26 [grpcio]\n",
      "   -------------------- ------------------- 13/26 [grpcio]\n",
      "   -------------------- ------------------- 13/26 [grpcio]\n",
      "   --------------------- ------------------ 14/26 [google-pasta]\n",
      "   --------------------- ------------------ 14/26 [google-pasta]\n",
      "   ----------------------- ---------------- 15/26 [gast]\n",
      "   ------------------------ --------------- 16/26 [absl-py]\n",
      "   ------------------------ --------------- 16/26 [absl-py]\n",
      "   ------------------------ --------------- 16/26 [absl-py]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   -------------------------- ------------- 17/26 [tensorboard]\n",
      "   --------------------------- ------------ 18/26 [optree]\n",
      "   --------------------------- ------------ 18/26 [optree]\n",
      "   --------------------------- ------------ 18/26 [optree]\n",
      "   ------------------------------ --------- 20/26 [markdown-it-py]\n",
      "   ------------------------------ --------- 20/26 [markdown-it-py]\n",
      "   ------------------------------ --------- 20/26 [markdown-it-py]\n",
      "   ------------------------------ --------- 20/26 [markdown-it-py]\n",
      "   ------------------------------ --------- 20/26 [markdown-it-py]\n",
      "   ------------------------------ --------- 20/26 [markdown-it-py]\n",
      "   ------------------------------ --------- 20/26 [markdown-it-py]\n",
      "   ------------------------------ --------- 20/26 [markdown-it-py]\n",
      "   -------------------------------- ------- 21/26 [h5py]\n",
      "   -------------------------------- ------- 21/26 [h5py]\n",
      "   -------------------------------- ------- 21/26 [h5py]\n",
      "   -------------------------------- ------- 21/26 [h5py]\n",
      "   -------------------------------- ------- 21/26 [h5py]\n",
      "   -------------------------------- ------- 21/26 [h5py]\n",
      "   -------------------------------- ------- 21/26 [h5py]\n",
      "   -------------------------------- ------- 21/26 [h5py]\n",
      "   ----------------------------------- ---- 23/26 [rich]\n",
      "   ----------------------------------- ---- 23/26 [rich]\n",
      "   ----------------------------------- ---- 23/26 [rich]\n",
      "   ----------------------------------- ---- 23/26 [rich]\n",
      "   ----------------------------------- ---- 23/26 [rich]\n",
      "   ----------------------------------- ---- 23/26 [rich]\n",
      "   ----------------------------------- ---- 23/26 [rich]\n",
      "   ----------------------------------- ---- 23/26 [rich]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   ------------------------------------ --- 24/26 [keras]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   -------------------------------------- - 25/26 [tensorflow]\n",
      "   ---------------------------------------- 26/26 [tensorflow]\n",
      "\n",
      "Successfully installed absl-py-2.3.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.73.0 h5py-3.14.0 keras-3.10.0 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.1.0 numpy-2.1.3 opt-einsum-3.4.0 optree-0.16.0 protobuf-5.29.5 rich-14.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.1.0 typing-extensions-4.14.0 wheel-0.45.1 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5766bc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in .\\.venv\\lib\\site-packages (from opencv-python) (2.1.3)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65e264c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f86859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=(224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1083b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = \"./data/train\"\n",
    "val_data = \"./data/val\"\n",
    "test_data = \"./data/test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b9dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Salmonella', 'New Castle Disease', 'Coccidiosis', 'Healthy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9899ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct relative paths\n",
    "train_data = \"archive/data/data/train\"\n",
    "val_data = \"archive/data/data/val\"\n",
    "test_data = \"archive/data/data/test\"\n",
    "\n",
    "# Make sure you define this\n",
    "labels = ['Coccidiosis', 'Healthy', 'New Castle Disease', 'Salmonella']\n",
    "\n",
    "# Function to read image data\n",
    "def read_data(folder):\n",
    "    data, label, paths = [], [], []\n",
    "\n",
    "    for l in labels:\n",
    "        path = f\"{folder}/{l}/\"\n",
    "        folder_data = os.listdir(path)[:500]\n",
    "\n",
    "        for image_path in folder_data:\n",
    "            img = cv2.imread(path + image_path)\n",
    "            data.append(img)\n",
    "            label.append(l)\n",
    "            paths.append(os.path.join(folder, l, image_path))\n",
    "\n",
    "    return data, label, paths\n",
    "\n",
    "# Call the function\n",
    "all_data, all_labels, all_paths = read_data(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3129edab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[217, 212, 211], [221, 216, 215], [225, 218,...</td>\n",
       "      <td>archive/data/data/train\\Coccidiosis\\cocci.0.jpg</td>\n",
       "      <td>Coccidiosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[200, 180, 199], [173, 161, 181], [83, 83, 1...</td>\n",
       "      <td>archive/data/data/train\\Coccidiosis\\cocci.0.jp...</td>\n",
       "      <td>Coccidiosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[78, 145, 130], [78, 144, 133], [79, 145, 14...</td>\n",
       "      <td>archive/data/data/train\\Coccidiosis\\cocci.0.jp...</td>\n",
       "      <td>Coccidiosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[11, 40, 44], [173, 204, 207], [197, 229, 23...</td>\n",
       "      <td>archive/data/data/train\\Coccidiosis\\cocci.0.jp...</td>\n",
       "      <td>Coccidiosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[192, 191, 200], [190, 192, 200], [206, 212,...</td>\n",
       "      <td>archive/data/data/train\\Coccidiosis\\cocci.0.jp...</td>\n",
       "      <td>Coccidiosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>[[[130, 144, 156], [127, 139, 151], [119, 127,...</td>\n",
       "      <td>archive/data/data/train\\Salmonella\\pcrsalmo.10...</td>\n",
       "      <td>Salmonella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>[[[244, 215, 194], [45, 20, 0], [220, 203, 184...</td>\n",
       "      <td>archive/data/data/train\\Salmonella\\pcrsalmo.10...</td>\n",
       "      <td>Salmonella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>[[[182, 160, 149], [183, 162, 154], [146, 124,...</td>\n",
       "      <td>archive/data/data/train\\Salmonella\\pcrsalmo.10...</td>\n",
       "      <td>Salmonella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>[[[81, 97, 113], [65, 81, 97], [39, 52, 68], [...</td>\n",
       "      <td>archive/data/data/train\\Salmonella\\pcrsalmo.10...</td>\n",
       "      <td>Salmonella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>[[[188, 185, 181], [174, 171, 167], [150, 145,...</td>\n",
       "      <td>archive/data/data/train\\Salmonella\\pcrsalmo.10...</td>\n",
       "      <td>Salmonella</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  \\\n",
       "0     [[[217, 212, 211], [221, 216, 215], [225, 218,...   \n",
       "1     [[[200, 180, 199], [173, 161, 181], [83, 83, 1...   \n",
       "2     [[[78, 145, 130], [78, 144, 133], [79, 145, 14...   \n",
       "3     [[[11, 40, 44], [173, 204, 207], [197, 229, 23...   \n",
       "4     [[[192, 191, 200], [190, 192, 200], [206, 212,...   \n",
       "...                                                 ...   \n",
       "1995  [[[130, 144, 156], [127, 139, 151], [119, 127,...   \n",
       "1996  [[[244, 215, 194], [45, 20, 0], [220, 203, 184...   \n",
       "1997  [[[182, 160, 149], [183, 162, 154], [146, 124,...   \n",
       "1998  [[[81, 97, 113], [65, 81, 97], [39, 52, 68], [...   \n",
       "1999  [[[188, 185, 181], [174, 171, 167], [150, 145,...   \n",
       "\n",
       "                                                   path        label  \n",
       "0       archive/data/data/train\\Coccidiosis\\cocci.0.jpg  Coccidiosis  \n",
       "1     archive/data/data/train\\Coccidiosis\\cocci.0.jp...  Coccidiosis  \n",
       "2     archive/data/data/train\\Coccidiosis\\cocci.0.jp...  Coccidiosis  \n",
       "3     archive/data/data/train\\Coccidiosis\\cocci.0.jp...  Coccidiosis  \n",
       "4     archive/data/data/train\\Coccidiosis\\cocci.0.jp...  Coccidiosis  \n",
       "...                                                 ...          ...  \n",
       "1995  archive/data/data/train\\Salmonella\\pcrsalmo.10...   Salmonella  \n",
       "1996  archive/data/data/train\\Salmonella\\pcrsalmo.10...   Salmonella  \n",
       "1997  archive/data/data/train\\Salmonella\\pcrsalmo.10...   Salmonella  \n",
       "1998  archive/data/data/train\\Salmonella\\pcrsalmo.10...   Salmonella  \n",
       "1999  archive/data/data/train\\Salmonella\\pcrsalmo.10...   Salmonella  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame({\n",
    "    'image': all_data,\n",
    "    'path': all_paths,\n",
    "    'label': all_labels\n",
    "})\n",
    "\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da3c4274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading test data\n",
    "all_data, all_labels, all_paths = read_data(test_data)\n",
    "\n",
    "# Creating test DataFrame\n",
    "test_df = pd.DataFrame({\n",
    "    'image': all_data,\n",
    "    'path': all_paths,\n",
    "    'label': all_labels\n",
    "})\n",
    "\n",
    "# Reading validation data\n",
    "all_data, all_labels, all_paths = read_data(val_data)\n",
    "\n",
    "# Creating validation DataFrame\n",
    "val_df = pd.DataFrame({\n",
    "    'image': all_data,\n",
    "    'path': all_paths,\n",
    "    'label': all_labels\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa147519",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (c:\\smartinternz\\.venv\\Lib\\site-packages\\keras\\preprocessing\\image\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Create an instance of ImageDataGenerator\u001b[39;00m\n\u001b[32m      4\u001b[39m gen = ImageDataGenerator()\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (c:\\smartinternz\\.venv\\Lib\\site-packages\\keras\\preprocessing\\image\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an instance of ImageDataGenerator\n",
    "gen = ImageDataGenerator()\n",
    "\n",
    "# Train data generator\n",
    "train_gen = gen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    seed=123,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Test data generator\n",
    "test_gen = gen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    seed=123,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "val_gen = gen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    seed=123,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4081b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5e2e59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 validated image filenames belonging to 4 classes.\n",
      "Found 2000 validated image filenames belonging to 4 classes.\n",
      "Found 2000 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of ImageDataGenerator\n",
    "gen = ImageDataGenerator()\n",
    "\n",
    "# Train data generator\n",
    "train_gen = gen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    seed=123,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Test data generator\n",
    "test_gen = gen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    seed=123,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    batch_size=32\n",
    ")\n",
    "# Validation data generator\n",
    "val_gen = gen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    seed=123,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6a74ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load pre-trained VGG16 model without top layer\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE, weights='imagenet', include_top=False)\n",
    "\n",
    "# Freeze the layers\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top of VGG16\n",
    "x = vgg.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=vgg.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True\n",
    ")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.2, patience=3, min_lr=1e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4e04f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> \n",
       "\n",
       " block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> \n",
       "\n",
       " block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> \n",
       "\n",
       " block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> \n",
       "\n",
       " block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> \n",
       "\n",
       " block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> \n",
       "\n",
       " block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> \n",
       "\n",
       " block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> \n",
       "\n",
       " block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
       "\n",
       " block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
       "\n",
       " block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
       "\n",
       " block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
       "\n",
       " block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> \n",
       "\n",
       " block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " global_average_pooling2d         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)                                               \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> \n",
       "\n",
       " batch_normalization              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> \n",
       "\n",
       " batch_normalization_1            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,052</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer (\u001b[38;5;33mInputLayer\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)            \u001b[38;5;34m1,792\u001b[0m \n",
       "\n",
       " block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)           \u001b[38;5;34m36,928\u001b[0m \n",
       "\n",
       " block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)          \u001b[38;5;34m73,856\u001b[0m \n",
       "\n",
       " block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)         \u001b[38;5;34m147,584\u001b[0m \n",
       "\n",
       " block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m295,168\u001b[0m \n",
       "\n",
       " block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m590,080\u001b[0m \n",
       "\n",
       " block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)           \u001b[38;5;34m590,080\u001b[0m \n",
       "\n",
       " block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         \u001b[38;5;34m1,180,160\u001b[0m \n",
       "\n",
       " block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         \u001b[38;5;34m2,359,808\u001b[0m \n",
       "\n",
       " block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)         \u001b[38;5;34m2,359,808\u001b[0m \n",
       "\n",
       " block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         \u001b[38;5;34m2,359,808\u001b[0m \n",
       "\n",
       " block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         \u001b[38;5;34m2,359,808\u001b[0m \n",
       "\n",
       " block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)         \u001b[38;5;34m2,359,808\u001b[0m \n",
       "\n",
       " block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " global_average_pooling2d         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       " (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)                                               \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                  \u001b[38;5;34m525,312\u001b[0m \n",
       "\n",
       " batch_normalization              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                    \u001b[38;5;34m4,096\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                   \u001b[38;5;34m524,800\u001b[0m \n",
       "\n",
       " batch_normalization_1            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                     \u001b[38;5;34m2,048\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                       \u001b[38;5;34m2,052\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,772,996</span> (60.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,772,996\u001b[0m (60.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,055,236</span> (4.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,055,236\u001b[0m (4.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,717,760</span> (56.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,717,760\u001b[0m (56.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af70836c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1023s\u001b[0m 16s/step - accuracy: 0.6980 - loss: 1.0382 - val_accuracy: 0.6235 - val_loss: 1.9957 - learning_rate: 0.0010\n",
      "Epoch 2/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m588s\u001b[0m 9s/step - accuracy: 0.8323 - loss: 0.5266 - val_accuracy: 0.6645 - val_loss: 1.7687 - learning_rate: 0.0010\n",
      "Epoch 3/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1138s\u001b[0m 18s/step - accuracy: 0.8692 - loss: 0.4176 - val_accuracy: 0.6515 - val_loss: 1.6698 - learning_rate: 0.0010\n",
      "Epoch 4/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 10s/step - accuracy: 0.8854 - loss: 0.3450 - val_accuracy: 0.6640 - val_loss: 1.7512 - learning_rate: 0.0010\n",
      "Epoch 5/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m714s\u001b[0m 11s/step - accuracy: 0.8849 - loss: 0.3429 - val_accuracy: 0.6660 - val_loss: 1.6841 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "r = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=5,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f425aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m80134624/80134624\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "vgg1 = VGG19(input_shape=IMAGE_SIZE, weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in vgg1.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(vgg1.output)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model1 = Model(inputs=vgg1.input, outputs=prediction)\n",
    "\n",
    "model1.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e1c8ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 0us/step\n",
      "Epoch 1/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 4s/step - accuracy: 0.6674 - loss: 5.0701 - val_accuracy: 0.6670 - val_loss: 7.1793\n",
      "Epoch 2/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 6s/step - accuracy: 0.9435 - loss: 0.7099 - val_accuracy: 0.6785 - val_loss: 8.4427\n",
      "Epoch 3/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 7s/step - accuracy: 0.9728 - loss: 0.2547 - val_accuracy: 0.6940 - val_loss: 7.6758\n",
      "Epoch 4/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 7s/step - accuracy: 0.9855 - loss: 0.1550 - val_accuracy: 0.6990 - val_loss: 9.1042\n",
      "Epoch 5/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 7s/step - accuracy: 0.9849 - loss: 0.1206 - val_accuracy: 0.6935 - val_loss: 9.2576\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "# Load ResNet50 without top layer\n",
    "res = ResNet50(input_shape=IMAGE_SIZE, weights='imagenet', include_top=False)\n",
    "\n",
    "# Freeze base layers\n",
    "for layer in res.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classifier\n",
    "x = Flatten()(res.output)\n",
    "prediction = Dense(4, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model2 = Model(inputs=res.input, outputs=prediction)\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "r = model2.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f10aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def predictor(model, test_gen):\n",
    "    classes = list(test_gen.class_indices.keys())\n",
    "    class_count = len(classes)\n",
    "\n",
    "    preds = model.predict(test_gen, verbose=1)\n",
    "    errors = 0\n",
    "    pred_indices = []\n",
    "    test_count = len(preds)\n",
    "\n",
    "    for i, p in enumerate(preds):\n",
    "        pred_index = np.argmax(p)\n",
    "        pred_indices.append(pred_index)\n",
    "        true_index = test_gen.labels[i]\n",
    "        if pred_index != true_index:\n",
    "            errors += 1\n",
    "\n",
    "    accuracy = (test_count - errors) * 100 / test_count\n",
    "    ytrue = np.array(test_gen.labels, dtype='int')\n",
    "    ypred = np.array(pred_indices, dtype='int')\n",
    "\n",
    "    msg = f'There were {errors} errors in {test_count} tests for an accuracy of {accuracy:6.2f}'\n",
    "    print(msg)\n",
    "\n",
    "    cm = confusion_matrix(ytrue, ypred)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)\n",
    "    plt.xticks(np.arange(class_count) + 0.5, classes, rotation=90)\n",
    "    plt.yticks(np.arange(class_count) + 0.5, classes, rotation=0)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Classification report\n",
    "    clr = classification_report(ytrue, ypred, target_names=classes, digits=4)\n",
    "    print(\"Classification Report:\\n-----------------------\\n\", clr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d367486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\smartinternz\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 5s/step\n",
      "There were 1476 errors in 2000 tests for an accuracy of  26.20\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "-----------------------\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       Coccidiosis     0.2523    0.2740    0.2627       500\n",
      "           Healthy     0.2737    0.3460    0.3057       500\n",
      "New Castle Disease     0.2440    0.1640    0.1962       500\n",
      "        Salmonella     0.2699    0.2640    0.2669       500\n",
      "\n",
      "          accuracy                         0.2620      2000\n",
      "         macro avg     0.2600    0.2620    0.2579      2000\n",
      "      weighted avg     0.2600    0.2620    0.2579      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor(model,test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df806e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb5c1cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in .\\.venv\\lib\\site-packages (from keras-tuner) (3.10.0)\n",
      "Requirement already satisfied: packaging in .\\.venv\\lib\\site-packages (from keras-tuner) (25.0)\n",
      "Requirement already satisfied: requests in .\\.venv\\lib\\site-packages (from keras-tuner) (2.32.4)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in .\\.venv\\lib\\site-packages (from keras->keras-tuner) (2.3.0)\n",
      "Requirement already satisfied: numpy in .\\.venv\\lib\\site-packages (from keras->keras-tuner) (2.1.3)\n",
      "Requirement already satisfied: rich in .\\.venv\\lib\\site-packages (from keras->keras-tuner) (14.0.0)\n",
      "Requirement already satisfied: namex in .\\.venv\\lib\\site-packages (from keras->keras-tuner) (0.1.0)\n",
      "Requirement already satisfied: h5py in .\\.venv\\lib\\site-packages (from keras->keras-tuner) (3.14.0)\n",
      "Requirement already satisfied: optree in .\\.venv\\lib\\site-packages (from keras->keras-tuner) (0.16.0)\n",
      "Requirement already satisfied: ml-dtypes in .\\.venv\\lib\\site-packages (from keras->keras-tuner) (0.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in .\\.venv\\lib\\site-packages (from optree->keras->keras-tuner) (4.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests->keras-tuner) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\.venv\\lib\\site-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests->keras-tuner) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\.venv\\lib\\site-packages (from requests->keras-tuner) (2025.6.15)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in .\\.venv\\lib\\site-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in .\\.venv\\lib\\site-packages (from rich->keras->keras-tuner) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in .\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "\n",
      "   ---------------------------------------- 0/2 [kt-legacy]\n",
      "   -------------------- ------------------- 1/2 [keras-tuner]\n",
      "   -------------------- ------------------- 1/2 [keras-tuner]\n",
      "   -------------------- ------------------- 1/2 [keras-tuner]\n",
      "   -------------------- ------------------- 1/2 [keras-tuner]\n",
      "   -------------------- ------------------- 1/2 [keras-tuner]\n",
      "   -------------------- ------------------- 1/2 [keras-tuner]\n",
      "   -------------------- ------------------- 1/2 [keras-tuner]\n",
      "   -------------------- ------------------- 1/2 [keras-tuner]\n",
      "   -------------------- ------------------- 1/2 [keras-tuner]\n",
      "   ---------------------------------------- 2/2 [keras-tuner]\n",
      "\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "# Run this command in the terminal or notebook cell\n",
    "!pip install keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1840698f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayas\\AppData\\Local\\Temp\\ipykernel_17424\\1337601089.py:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "import kerastuner as kt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b16aea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 Complete [00h 55m 06s]\n",
      "val_accuracy: 0.6984999775886536\n",
      "\n",
      "Best val_accuracy So Far: 0.7064999938011169\n",
      "Total elapsed time: 01h 46m 25s\n",
      "\n",
      "Search: Running Trial #8\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "512               |1024              |units\n",
      "2.5073e-05        |0.00015104        |learning_rate\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 3s/step - accuracy: 0.3546 - loss: 1.4439 - val_accuracy: 0.5830 - val_loss: 1.0210\n",
      "Epoch 2/2\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7521 - loss: 0.7571"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m stop_early = tf.keras.callbacks.EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m5\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Run the hyperparameter search\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstop_early\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[39m, in \u001b[36mBaseTuner.search\u001b[39m\u001b[34m(self, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_begin(trial)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_end(trial)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.on_search_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:274\u001b[39m, in \u001b[36mBaseTuner._try_run_and_update_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, *fit_args, **fit_kwargs):\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m         trial.status = trial_module.TrialStatus.COMPLETED\n\u001b[32m    276\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:239\u001b[39m, in \u001b[36mBaseTuner._run_and_update_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, *fit_args, **fit_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[32m    241\u001b[39m         \u001b[38;5;28mself\u001b[39m.oracle.objective.name\n\u001b[32m    242\u001b[39m     ):\n\u001b[32m    243\u001b[39m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[32m    244\u001b[39m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[32m    245\u001b[39m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[32m    246\u001b[39m         warnings.warn(\n\u001b[32m    247\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe use case of calling \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    254\u001b[39m             stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    255\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py:427\u001b[39m, in \u001b[36mHyperband.run_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    425\u001b[39m     fit_kwargs[\u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m] = hp.values[\u001b[33m\"\u001b[39m\u001b[33mtuner/epochs\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    426\u001b[39m     fit_kwargs[\u001b[33m\"\u001b[39m\u001b[33minitial_epoch\u001b[39m\u001b[33m\"\u001b[39m] = hp.values[\u001b[33m\"\u001b[39m\u001b[33mtuner/initial_epoch\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[39m, in \u001b[36mTuner.run_trial\u001b[39m\u001b[34m(self, trial, *args, **kwargs)\u001b[39m\n\u001b[32m    312\u001b[39m     callbacks.append(model_checkpoint)\n\u001b[32m    313\u001b[39m     copied_kwargs[\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m] = callbacks\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     obj_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m     histories.append(obj_value)\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[39m, in \u001b[36mTuner._build_and_fit_model\u001b[39m\u001b[34m(self, trial, *args, **kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m hp = trial.hyperparameters\n\u001b[32m    232\u001b[39m model = \u001b[38;5;28mself\u001b[39m._try_build(hp)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.config.multi_backend():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[39m, in \u001b[36mHyperModel.fit\u001b[39m\u001b[34m(self, hp, model, *args, **kwargs)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, *args, **kwargs):\n\u001b[32m    126\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[32m    127\u001b[39m \n\u001b[32m    128\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    147\u001b[39m \u001b[33;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:401\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_eval_epoch_iterator\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    391\u001b[39m     \u001b[38;5;28mself\u001b[39m._eval_epoch_iterator = TFEpochIterator(\n\u001b[32m    392\u001b[39m         x=val_x,\n\u001b[32m    393\u001b[39m         y=val_y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    399\u001b[39m         shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    400\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m val_logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m val_logs = {\n\u001b[32m    412\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mval_\u001b[39m\u001b[33m\"\u001b[39m + name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs.items()\n\u001b[32m    413\u001b[39m }\n\u001b[32m    414\u001b[39m epoch_logs.update(val_logs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:489\u001b[39m, in \u001b[36mTensorFlowTrainer.evaluate\u001b[39m\u001b[34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    488\u001b[39m     callbacks.on_test_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    490\u001b[39m     callbacks.on_test_batch_end(step, logs)\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_evaluating:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Define the model-building function for Keras Tuner\n",
    "def build_model(hp):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(hp.Int('units', min_value=512, max_value=2048, step=512), activation='relu')(x)\n",
    "    predictions = Dense(4, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Freeze the base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "                      hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='LOG', default=1e-3)),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "# Define early stopping callback\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Run the hyperparameter search\n",
    "tuner.search(train_gen, epochs=5, validation_data=val_gen, callbacks=[stop_early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ba0ca48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 14m 50s]\n",
      "val_accuracy: 0.7164999842643738\n",
      "\n",
      "Best val_accuracy So Far: 0.7164999842643738\n",
      "Total elapsed time: 00h 14m 50s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "512               |1024              |units\n",
      "0.0027371         |0.0035755         |learning_rate\n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 5s/step - accuracy: 0.5815 - loss: 2.5093 - val_accuracy: 0.6845 - val_loss: 1.2496\n",
      "Epoch 2/5\n",
      "\u001b[1m 9/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3:46\u001b[0m 4s/step - accuracy: 0.8661 - loss: 0.3181"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m stop_early = tf.keras.callbacks.EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m3\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Run the tuner search\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m             \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstop_early\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Retrieve the best model\u001b[39;00m\n\u001b[32m     48\u001b[39m best_model = tuner.get_best_models(num_models=\u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[39m, in \u001b[36mBaseTuner.search\u001b[39m\u001b[34m(self, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_begin(trial)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_end(trial)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.on_search_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:274\u001b[39m, in \u001b[36mBaseTuner._try_run_and_update_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, *fit_args, **fit_kwargs):\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m         trial.status = trial_module.TrialStatus.COMPLETED\n\u001b[32m    276\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:239\u001b[39m, in \u001b[36mBaseTuner._run_and_update_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, *fit_args, **fit_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[32m    241\u001b[39m         \u001b[38;5;28mself\u001b[39m.oracle.objective.name\n\u001b[32m    242\u001b[39m     ):\n\u001b[32m    243\u001b[39m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[32m    244\u001b[39m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[32m    245\u001b[39m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[32m    246\u001b[39m         warnings.warn(\n\u001b[32m    247\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe use case of calling \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    254\u001b[39m             stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    255\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[39m, in \u001b[36mTuner.run_trial\u001b[39m\u001b[34m(self, trial, *args, **kwargs)\u001b[39m\n\u001b[32m    312\u001b[39m     callbacks.append(model_checkpoint)\n\u001b[32m    313\u001b[39m     copied_kwargs[\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m] = callbacks\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     obj_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m     histories.append(obj_value)\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[39m, in \u001b[36mTuner._build_and_fit_model\u001b[39m\u001b[34m(self, trial, *args, **kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m hp = trial.hyperparameters\n\u001b[32m    232\u001b[39m model = \u001b[38;5;28mself\u001b[39m._try_build(hp)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.config.multi_backend():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[39m, in \u001b[36mHyperModel.fit\u001b[39m\u001b[34m(self, hp, model, *args, **kwargs)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, *args, **kwargs):\n\u001b[32m    126\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[32m    127\u001b[39m \n\u001b[32m    128\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    147\u001b[39m \u001b[33;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\smartinternz\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from kerastuner.tuners import RandomSearch  # if you get a warning, use 'from keras_tuner import RandomSearch'\n",
    "\n",
    "# Define the model-building function\n",
    "def build_model(hp):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(hp.Int('units', min_value=512, max_value=2048, step=512), activation='relu')(x)\n",
    "    predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Freeze base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "                      hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='LOG', default=1e-3)),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Initialize the tuner (RandomSearch)\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Try only 5 different combinations\n",
    "    directory='my_dir',\n",
    "    project_name='resnet50_tuning'\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Run the tuner search\n",
    "tuner.search(train_gen, \n",
    "             epochs=5, \n",
    "             validation_data=val_gen, \n",
    "             callbacks=[stop_early])\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Optionally, evaluate the best model\n",
    "loss, accuracy = best_model.evaluate(val_gen)\n",
    "print(f\"Best Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "685fe1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 07m 48s]\n",
      "val_accuracy: 0.6949999928474426\n",
      "\n",
      "Best val_accuracy So Far: 0.7124999761581421\n",
      "Total elapsed time: 00h 15m 21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\smartinternz\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.7151 - loss: 1.0355\n",
      "Best Model Accuracy: 0.7125\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras_tuner.tuners import RandomSearch  # Use keras_tuner if the other fails\n",
    "\n",
    "# Define the model-building function\n",
    "def build_model(hp):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(hp.Int('units', min_value=512, max_value=1024, step=256), activation='relu')(x)\n",
    "    predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Freeze base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n",
    "        ),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize the tuner with 2 trials only\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=2,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='resnet50_2epoch'\n",
    ")\n",
    "\n",
    "# Early stopping (optional)\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "# Run hyperparameter tuning with only 2 epochs\n",
    "tuner.search(train_gen, \n",
    "             epochs=2, \n",
    "             validation_data=val_gen, \n",
    "             callbacks=[stop_early])\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the best model\n",
    "loss, accuracy = best_model.evaluate(val_gen)\n",
    "print(f\"Best Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5da80940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal number of units in the dense layer is 768 and the optimal learning rate for the optimizer is 0.0009249366576101544.\n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 3s/step - accuracy: 0.6923 - loss: 0.9055 - val_accuracy: 0.7070 - val_loss: 1.1852\n",
      "Epoch 2/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 3s/step - accuracy: 0.9513 - loss: 0.1611 - val_accuracy: 0.7220 - val_loss: 1.2611\n",
      "Epoch 3/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 3s/step - accuracy: 0.9762 - loss: 0.0822 - val_accuracy: 0.7015 - val_loss: 1.6490\n",
      "Epoch 4/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 3s/step - accuracy: 0.9895 - loss: 0.0464 - val_accuracy: 0.7200 - val_loss: 1.4285\n",
      "Epoch 5/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 3s/step - accuracy: 0.9970 - loss: 0.0234 - val_accuracy: 0.7230 - val_loss: 1.4954\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Print the optimal hyperparameters\n",
    "print(f\"\"\"\n",
    "The optimal number of units in the dense layer is {best_hps.get('units')} and the optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n",
    "\n",
    "# Build the model with the optimal hyperparameters\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the final model\n",
    "history = model.fit(train_gen, validation_data=val_gen, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5055bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen.class_indices.keys()\n",
    "\n",
    "# Output:\n",
    "# dict_keys(['Coccidiosis', 'Healthy', 'New Castle Disease', 'Salmonella'])\n",
    "\n",
    "labels = ['Coccidiosis', 'Healthy', 'New Castle Disease', 'Salmonella']\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def get_model_prediction(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    predictions = model.predict(x, verbose=0)\n",
    "    return labels[predictions.argmax()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "45ba9d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salmonella'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_prediction('archive/data/data/test/Coccidiosis/cocci.0.jpg_aug33.JPG')\n",
    "# Output: 'Coccidiosis'\n",
    "\n",
    "get_model_prediction('archive/data/data/test/Healthy/healthy.1003.jpg_aug47.JPG')\n",
    "# Output: 'Healthy'\n",
    "\n",
    "get_model_prediction('archive/data/data/test/New Castle Disease/ncd.1.jpg_aug197.JPG')\n",
    "# Output: 'New Castle Disease'\n",
    "\n",
    "get_model_prediction('archive/data/data/test/Salmonella/pcrsalmo.111.jpg_aug29.JPG')\n",
    "# Output: 'Salmonella'\n",
    "\n",
    "get_model_prediction('archive/data/data/test/Salmonella/pcrsalmo.115.jpg_aug28.JPG')\n",
    "# Output: 'Salmonella'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
